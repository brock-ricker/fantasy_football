{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master API Nptebook\n",
    "* Functions for downloading data using APIs from myfantasyleague.com for fantasy football data\n",
    "* Brock Ricker\n",
    "* https://github.com/brock-ricker\n",
    "* Created 07/01/2022\n",
    "* v1.1: 07/09/2022 - added year to points allowed, and year/week to projected score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Variables\n",
    "\n",
    "#define user agent for my fantasy API use\n",
    "agent = \"brockr1\"\n",
    "#my Fantasy League, League ID\n",
    "league_id = 20896\n",
    "#create db name - this will be SQLite\n",
    "db_name = \"test\"\n",
    "#Years of league history\n",
    "years = [2017,2018,2019,2020,2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sqlite engine for a db using name defined above\n",
    "engine = create_engine(f\"sqlite:///{db_name}.db\", echo=False)\n",
    "#create connection to the engine\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup logging info\n",
    "#naming log based on date/time\n",
    "t=time.localtime()\n",
    "date = time.strftime(\"%y%m%d_%H%M%S\", t)\n",
    "#logging settings\n",
    "logging.basicConfig(filename=f\"{date}.log\", encoding='utf-8', level=logging.INFO)\n",
    "#initialize errors variable = False\n",
    "errors = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining pause function (for pause time between yearly API pulls)\n",
    "def pause(t=2):\n",
    "    print(\"pausing to prevent lockout of API\")\n",
    "    time.sleep(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining pause function (for pause time between weekly API pulls)\n",
    "def short_pause():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Results\n",
    "* This section covers functions from Weekly Results API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for cleaning players table\n",
    "def df_players_cleaner(df_players):\n",
    "\n",
    "    df_players = df_players.astype({\n",
    "        \"id\": int,\n",
    "        \"shouldStart\": int,\n",
    "        \"score\": float\n",
    "    })\n",
    "\n",
    "    df_players = df_players.rename(columns = {\"shouldStart\": \"should_start\"})\n",
    "\n",
    "    return df_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for cleaning df_teams\n",
    "def df_team_cleaner(df_teams):\n",
    "    \n",
    "    df_teams.drop(columns = [\"player\",\"comments\"],inplace=True)\n",
    "    \n",
    "    df_teams = df_teams.astype({\n",
    "        \"score\": float,\n",
    "        \"isHome\": int,\n",
    "        \"id\": int,\n",
    "    })\n",
    "\n",
    "    df_teams = df_teams.rename(columns = {\"isHome\": \"is_home\"})\n",
    "\n",
    "    return df_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for creating matchups table - !must run df_team_cleaner first!\n",
    "def matchup_table_generator(df_teams):\n",
    "    \n",
    "    total_teams = len(df_teams)\n",
    "    team1 = list(range(0,total_teams-1,2))\n",
    "    team2 = list(range(1,total_teams,2))\n",
    "\n",
    "    df_matchups = pd.DataFrame({\n",
    "        \"team1_id\":list(df_teams.iloc[team1][\"id\"]),\n",
    "        \"team1_score\":list(df_teams.iloc[team1][\"score\"]),\n",
    "        \"team2_id\":list(df_teams.iloc[team2][\"id\"]),\n",
    "        \"team2_score\":list(df_teams.iloc[team2][\"score\"])\n",
    "    })\n",
    "\n",
    "    df_matchups['winning_team'] = np.select([df_matchups['team1_score'] > df_matchups['team2_score'], df_matchups['team1_score'] < df_matchups['team2_score']], [df_matchups[\"team1_id\"],df_matchups[\"team2_id\"]], default=\"error\")\n",
    "\n",
    "    return df_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls weekly score data and saves to SQL server\n",
    "#creates following tables: weekly_players, weekly_teams, weekly_matchup\n",
    "def weekly_score_pull(years,agent,conn,league_id):\n",
    "    logging.info(\"----------------------------------------weekly_score_pull----------------------------------------\")\n",
    "    i = 1\n",
    "    for year in years:\n",
    "        if i>1:\n",
    "            pause()\n",
    "        \n",
    "        logging.info(f\"begin parsing year: {year}\")\n",
    "\n",
    "        request_url = f\"https://www54.myfantasyleague.com/{year}/export?L={league_id}&W=YTD&TYPE=weeklyResults&JSON=1&{agent}\"\n",
    "        req = requests.get(request_url)\n",
    "        logging.info(f\"connection results: {req}\")\n",
    "        req_data = req.json()\n",
    "            \n",
    "        weekly_results = req_data['allWeeklyResults']['weeklyResults']\n",
    "\n",
    "        for single_week in weekly_results:\n",
    "            if \"matchup\" not in single_week:\n",
    "                break\n",
    "            df_players = pd.json_normalize(single_week[\"matchup\"],record_path=[\"franchise\",\"player\"])\n",
    "            df_teams = pd.json_normalize(single_week[\"matchup\"],record_path=[\"franchise\"])\n",
    "            \n",
    "            #cleaning tables\n",
    "            df_players = df_players_cleaner(df_players)\n",
    "            df_teams = df_team_cleaner(df_teams)\n",
    "            df_matchups = matchup_table_generator(df_teams)\n",
    "\n",
    "            #adding weeks, years, regular_season to data_tables\n",
    "            df_players[\"week\"] = int(single_week[\"week\"])\n",
    "            df_players[\"year\"] = year\n",
    "            df_players[\"regular_season\"] = int(single_week[\"matchup\"][0][\"regularSeason\"])\n",
    "            \n",
    "            df_teams[\"week\"] = int(single_week[\"week\"])\n",
    "            df_teams[\"year\"] = year\n",
    "            df_teams[\"regular_season\"] = int(single_week[\"matchup\"][0][\"regularSeason\"])\n",
    "            \n",
    "            df_matchups[\"week\"] = int(single_week[\"week\"])\n",
    "            df_matchups[\"year\"] = year\n",
    "            df_matchups[\"regular_season\"] = int(single_week[\"matchup\"][0][\"regularSeason\"])        \n",
    "\n",
    "            #writting to SQL\n",
    "            df_players.to_sql(\"weekly_players\", conn, if_exists=\"append\");\n",
    "            df_teams.to_sql(\"weekly_teams\", conn, if_exists=\"append\");\n",
    "            df_matchups.to_sql(\"weekly_matchup\", conn, if_exists=\"append\");\n",
    "            week = single_week[\"week\"]\n",
    "            logging.info(f\"finished year: {year}, week: {week}\")\n",
    "        \n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function here\n",
    "weekly_score_pull(years,agent,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Players\n",
    "* This section covers functions from players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans simple player data \n",
    "def clean_simple_players(players):\n",
    "    players = players.astype({\"id\":int})\n",
    "    players.rename(columns = {\"status\":\"rookie\"},inplace = True)\n",
    "    players[\"rookie\"].replace({\"R\":\"yes\"},inplace = True)\n",
    "    players[\"rookie\"].fillna(\"No\", inplace= True)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls player data and saves to SQL server\n",
    "#creates following table: simple_players\n",
    "def simple_player_pull (years,agent,conn,league_id):\n",
    "    logging.info(\"----------------------------------------simple_player_pull----------------------------------------\")\n",
    "    i = 1\n",
    "    for year in years:\n",
    "        if i>1:\n",
    "            pause()\n",
    "            \n",
    "        logging.info(f\"begin parsing year: {year}\")\n",
    "        request_url = f\"https://www54.myfantasyleague.com/{year}/export?L={league_id}&TYPE=players&JSON=1&{agent}\"\n",
    "        req = requests.get(request_url)\n",
    "        req_data = req.json()\n",
    "        logging.info(f\"connection results: {req}\")\n",
    "        \n",
    "        players = pd.json_normalize(req_data[\"players\"],record_path=[\"player\"])\n",
    "        \n",
    "        players = clean_simple_players(players)\n",
    "        players[\"year\"] = year\n",
    "        \n",
    "        players.to_sql(\"simple_players\", conn, if_exists=\"append\")\n",
    "        i =i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin parsing year: 2017\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2018\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2019\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2020\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2021\n",
      "connection results: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#call function here\n",
    "simple_player_pull(years,agent,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADP\n",
    "* this section covers pulls from the ADP API (rookie and full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans ADP data\n",
    "def clean_adp(adp):\n",
    "    adp = adp.astype({\n",
    "        'minPick':int, \n",
    "        'maxPick':int, \n",
    "        'draftsSelectedIn':int, \n",
    "        'id':int, \n",
    "        'averagePick':float, \n",
    "        'rank':int,\n",
    "        'draftSelPct':int\n",
    "    })\n",
    "    return adp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls adp data and saves to SQL server\n",
    "#creates following table: adp\n",
    "def adp_pull (years,agent,conn):\n",
    "    logging.info(\"----------------------------------------adp_pull----------------------------------------\")\n",
    "    i = 1\n",
    "    for year in years:\n",
    "        if i>1:\n",
    "            pause()\n",
    "\n",
    "        logging.info(f\"begin parsing year: {year}\")\n",
    "        request_url = f\"https://api.myfantasyleague.com/{year}/export?TYPE=adp&JSON=1&{agent}&FCOUNT=12&&IS_KEEPER=N\"\n",
    "        req = requests.get(request_url)\n",
    "        req_data = req.json()\n",
    "        logging.info(f\"connection results: {req}\")\n",
    "        \n",
    "        adp = pd.json_normalize(req_data[\"adp\"],record_path=[\"player\"])\n",
    "\n",
    "        adp = clean_adp(adp)\n",
    "        \n",
    "        adp[\"year\"] = year\n",
    "        \n",
    "        adp.to_sql(\"adp\", conn, if_exists=\"append\")\n",
    "        i =i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function does not work yet due to missing data no the website\n",
    "def rookie_adp_pull (years,agent=agent,conn=conn):\n",
    "    rookie_adp = pd.DataFrame()\n",
    "    i = 1\n",
    "    for year in years:\n",
    "        if i>1:\n",
    "            pause()\n",
    "\n",
    "        print(\"begin parsing year:\",year)\n",
    "        request_url = f\"https://api.myfantasyleague.com/{year}/export?TYPE=adp&JSON=1&{agent}&FCOUNT=12&&IS_KEEPER=R\"\n",
    "        req = requests.get(request_url)\n",
    "        req_data = req.json()\n",
    "        print(\"connection results:\",req)\n",
    "        \n",
    "        rookie_adp = pd.json_normalize(req_data[\"adp\"],record_path=[\"player\"],errors=\"ignore\")\n",
    "\n",
    "        rookie_adp = clean_adp(rookie_adp)\n",
    "        \n",
    "        rookie_adp[\"year\"] = year\n",
    "        \n",
    "        rookie_adp.to_sql(\"rookie_adp\", conn, if_exists=\"append\")\n",
    "        i =i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin parsing year: 2017\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2018\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2019\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2020\n",
      "connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2021\n",
      "connection results: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#call function here\n",
    "adp_pull(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing 2018 data from website so this function is not called\n",
    "#rookie_adp_pull(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points Allowed\n",
    "* This section covers all the data from the points allowed API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans points allowed table\n",
    "def clean_points_allowed(points_allowed):\n",
    "    \n",
    "    #convert datatype\n",
    "    points_allowed = points_allowed.astype({\"points\":float})\n",
    "    #rename columns\n",
    "    points_allowed.rename(columns = {\"name\":\"pos\"},inplace=True)\n",
    "    #convert to points/week\n",
    "    points_allowed[\"points\"] = (points_allowed[\"points\"]/16).round(2)\n",
    "    #calculate total points and make into df\n",
    "    total_points = pd.DataFrame({\n",
    "        \"points\":[points_allowed[\"points\"].sum()],\n",
    "        \"pos\":[\"ALL\"]})\n",
    "    #add total points\n",
    "    points_allowed = pd.concat([points_allowed,total_points],ignore_index=True)\n",
    "\n",
    "    return points_allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls points allowed data and saves to SQL server\n",
    "#creates following table: points_allowed\n",
    "def points_allowed_pull(years,agent,conn,league_id):\n",
    "    logging.info(\"----------------------------------------points_allowed_pull----------------------------------------\")\n",
    "    i = 1\n",
    "    for year in years:\n",
    "        if i>1:\n",
    "            pause()\n",
    "\n",
    "        \n",
    "        logging.info(f\"begin parsing year: {year}\")\n",
    "        request_url = f\"https://www54.myfantasyleague.com/{year}/export?L={league_id}&TYPE=pointsAllowed&JSON=1&{agent}\"\n",
    "        req = requests.get(request_url)\n",
    "        logging.info(f\"connection results: {req}\")\n",
    "        req_data = req.json()\n",
    "            \n",
    "        teams = req_data['pointsAllowed'][\"team\"]\n",
    "\n",
    "        for team in teams:\n",
    "            points_allowed = pd.json_normalize(team,record_path=[\"position\"])\n",
    "\n",
    "            points_allowed = clean_points_allowed(points_allowed)\n",
    "\n",
    "            points_allowed[\"team\"] = team[\"id\"]\n",
    "            points_allowed[\"year\"] = year\n",
    "\n",
    "            points_allowed.to_sql(\"points_allowed\", conn, if_exists=\"append\")\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin parsing year: 2017\n",
      "year 2017 connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2018\n",
      "year 2018 connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2019\n",
      "year 2019 connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2020\n",
      "year 2020 connection results: <Response [200]>\n",
      "pausing to prevent lockout of API\n",
      "begin parsing year: 2021\n",
      "year 2021 connection results: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#call function here\n",
    "points_allowed_pull(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected Scores\n",
    "* This section covers all the data from the projected scores API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans projected scores table\n",
    "def clean_projected_scores(projected_scores):\n",
    "    #delete rows with blank entries\n",
    "    projected_scores = projected_scores.loc[~((projected_scores[\"score\"]==\"\") | (projected_scores[\"id\"]==\"\"))]\n",
    "    #convert datatypes\n",
    "    projected_scores = projected_scores.astype({\n",
    "    \"score\":float,\n",
    "    \"id\":int\n",
    "    })\n",
    "    #rename columns\n",
    "    projected_scores.rename(columns = {\"score\":\"projected_scores\"},inplace=True)\n",
    "    return projected_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls projected score data and saves to SQL server\n",
    "#creates following table: projected_scores_pull\n",
    "#very long pause due to numerous API requests\n",
    "def projected_scores_pull(years,agent,conn,league_id):\n",
    "    logging.info(\"----------------------------------------projected_scores_pull----------------------------------------\")\n",
    "    i = 1\n",
    "    for year in years:\n",
    "        if i>1:\n",
    "            pause(300)\n",
    "        \n",
    "        logging.info(f\"begin parsing year: {year}\")\n",
    "        weeks = list(range(1,19))\n",
    "        \n",
    "        for week in weeks:\n",
    "            logging.info(f\"parsing week: {week}\")\n",
    "            request_url = f\"https://www54.myfantasyleague.com/{year}/export?L={league_id}&W={week}&TYPE=projectedScores&JSON=1&{agent}\"\n",
    "            req = requests.get(request_url)\n",
    "            logging.info(f\"connection results: {req}\")\n",
    "            req_data = req.json()\n",
    "\n",
    "            projected_scores = pd.json_normalize(req_data[\"projectedScores\"],record_path=[\"playerScore\"])\n",
    "\n",
    "            projected_scores = clean_projected_scores(projected_scores)\n",
    "\n",
    "            projected_scores[\"week\"] = week\n",
    "            projected_scores[\"year\"] = year\n",
    "\n",
    "            projected_scores.to_sql(\"projected_scores\", conn, if_exists=\"append\")\n",
    "\n",
    "            short_pause()\n",
    "\n",
    "\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function here\n",
    "#In order to avoid to API lockout, this fucntion takes ~5 minutes per year\n",
    "projected_scores_pull(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League Info\n",
    "* covers all data from league info API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans league data\n",
    "def clean_league_teams(league_teams):\n",
    "    league_teams = league_teams[[\"icon\",\"name\",\"id\",\"logo\"]]\n",
    "    league_teams = league_teams.astype({\"id\":int})\n",
    "    return league_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls league data and saves to SQL server, this will replace any other entry in server\n",
    "#creates following table: league_teams\n",
    "def league_teams_pull(years,agent,conn,league_id):\n",
    "    logging.info(\"----------------------------------------league_teams_pull----------------------------------------\")\n",
    "    year = years[-1]\n",
    "    request_url = f\"https://www54.myfantasyleague.com/{year}/export?L={league_id}&TYPE=league&JSON=1&{agent}\"\n",
    "    req = requests.get(request_url)\n",
    "    logging.info(f\"connection results: {req}\")\n",
    "    req_data =req.json()\n",
    "    league_teams = pd.json_normalize(req_data[\"league\"][\"franchises\"],record_path = [\"franchise\"])\n",
    "\n",
    "    league_teams = clean_league_teams(league_teams)\n",
    "\n",
    "    league_teams.to_sql(\"league_teams\", conn, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin parsing:\n",
      "connection results: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#call function here, only 1 year is necesarry\n",
    "league_teams_pull(2022)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e573eb6a34c0b72ab40cadb87cb95ce8e491332939d43b3d79a40e464100df54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
